{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "0RU-WO7kdmMM",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.019138Z",
     "start_time": "2025-07-16T22:57:13.014625Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.distributed.pipelining import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import copy"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbapuQUeyE0S",
    "outputId": "7a20781d-293d-4fd2-d7f6-87ff7a0c0102",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.040159Z",
     "start_time": "2025-07-16T22:57:13.030108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "id": "RNUlQOuLfPqH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('../data/train.txt', header=None, sep=\";\")\n",
    "test_df = pd.read_csv('../data/test.txt', header=None, sep=\";\")\n",
    "val_df = pd.read_csv('../data/validation.txt', header=None, sep=\";\")"
   ],
   "metadata": {
    "id": "Uxc1ekBKd_gW",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.120510Z",
     "start_time": "2025-07-16T22:57:13.089249Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SF43L1KUejY5",
    "outputId": "f6aecec8-666a-41fe-c71d-43f4eaa94329",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.165100Z",
     "start_time": "2025-07-16T22:57:13.158261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   0        1\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "train_df[1].value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "_zxtKO9dxN4C",
    "outputId": "681d77f9-c01f-4c07-dc43-714eb8cfbcc0",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.266271Z",
     "start_time": "2025-07-16T22:57:13.260543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to make a encoder for emotions"
   ],
   "metadata": {
    "id": "f3YB8n2KxSw-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df[1])\n",
    "test_labels = label_encoder.transform(test_df[1])\n",
    "val_labels = label_encoder.transform(val_df[1])"
   ],
   "metadata": {
    "id": "4gEGhAejwi_f",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.341333Z",
     "start_time": "2025-07-16T22:57:13.332606Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "print(label_encoder.classes_)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itwoYT4vx6Yj",
    "outputId": "d4e17e39-752b-49ed-be1c-66e301783077",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:13.389272Z",
     "start_time": "2025-07-16T22:57:13.382382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model.eval()\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_texts = train_df[0].tolist()\n",
    "test_texts = test_df[0].tolist()\n",
    "val_texts = val_df[0].tolist()\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    batch_size = 32\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        encodings = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "\n",
    "        all_embeddings.append(cls_embeddings.cpu())\n",
    "\n",
    "    embeds = torch.cat(all_embeddings)\n",
    "    return embeds\n",
    "\n",
    "X_train_tensor = get_embeddings(train_texts)\n",
    "X_test_tensor = get_embeddings(test_texts)\n",
    "X_val_tensor = get_embeddings(val_texts)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhRiI4OQmroL",
    "outputId": "793cfc5b-15d3-4e21-a1ba-161a6c3d88e4",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:42.870694Z",
     "start_time": "2025-07-16T22:57:13.472437Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset & DataLoader"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:42.893716Z",
     "start_time": "2025-07-16T22:57:42.885123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "id": "6asL8Oorx9qL"
   }
  },
  {
   "metadata": {
    "id": "JCiBmf4Jx_hr",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:42.955518Z",
     "start_time": "2025-07-16T22:57:42.947016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FCNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_size=768, num_classes=6):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 256)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(128, num_classes)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc3(x)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:43.044747Z",
     "start_time": "2025-07-16T22:57:43.033650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, epochs=10, val_loader=None, patience=5):\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f}\", end=\"\")\n",
    "\n",
    "        if val_loader:\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, device, return_metrics=True)\n",
    "            print(f\" | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "            # Early stopping logic\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                best_model_wts = model.state_dict()\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                model.load_state_dict(best_model_wts)\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, \"../models/best_fcnn_model.pth\")\n",
    "                break\n",
    "        else:\n",
    "            print()"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:43.084350Z",
     "start_time": "2025-07-16T22:57:43.077781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, data_loader, criterion, device, label_encoder=None, return_metrics=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    if return_metrics:\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        return avg_loss, accuracy\n",
    "    else:\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_ if label_encoder else None))"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "id": "9xC9zAMz1Ru5",
    "ExecuteTime": {
     "end_time": "2025-07-16T22:57:43.146181Z",
     "start_time": "2025-07-16T22:57:43.137577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = FCNNModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T22:58:37.641801Z",
     "start_time": "2025-07-16T22:57:43.199523Z"
    }
   },
   "cell_type": "code",
   "source": "train(model, train_loader, optimizer, criterion, device, epochs=30, val_loader=test_loader, patience=5)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 679.6614 | Train Acc: 0.4857 | Val Loss: 1.1983 | Val Acc: 0.5445\n",
      "Epoch 2/30 | Train Loss: 608.1725 | Train Acc: 0.5433 | Val Loss: 1.1708 | Val Acc: 0.5615\n",
      "Epoch 3/30 | Train Loss: 576.5800 | Train Acc: 0.5605 | Val Loss: 1.0964 | Val Acc: 0.5850\n",
      "Epoch 4/30 | Train Loss: 559.8965 | Train Acc: 0.5748 | Val Loss: 1.0800 | Val Acc: 0.5935\n",
      "Epoch 5/30 | Train Loss: 548.3778 | Train Acc: 0.5844 | Val Loss: 1.0746 | Val Acc: 0.5875\n",
      "Epoch 6/30 | Train Loss: 535.3342 | Train Acc: 0.5940 | Val Loss: 1.0454 | Val Acc: 0.6020\n",
      "Epoch 7/30 | Train Loss: 526.6202 | Train Acc: 0.6006 | Val Loss: 1.0407 | Val Acc: 0.6035\n",
      "Epoch 8/30 | Train Loss: 521.5556 | Train Acc: 0.6059 | Val Loss: 1.0324 | Val Acc: 0.6130\n",
      "Epoch 9/30 | Train Loss: 514.3788 | Train Acc: 0.6085 | Val Loss: 1.0227 | Val Acc: 0.6075\n",
      "Epoch 10/30 | Train Loss: 507.1251 | Train Acc: 0.6176 | Val Loss: 1.0266 | Val Acc: 0.6145\n",
      "Epoch 11/30 | Train Loss: 501.4812 | Train Acc: 0.6175 | Val Loss: 1.0296 | Val Acc: 0.6065\n",
      "Epoch 12/30 | Train Loss: 497.4494 | Train Acc: 0.6239 | Val Loss: 1.0192 | Val Acc: 0.6110\n",
      "Epoch 13/30 | Train Loss: 491.4457 | Train Acc: 0.6281 | Val Loss: 1.0138 | Val Acc: 0.6045\n",
      "Epoch 14/30 | Train Loss: 488.5177 | Train Acc: 0.6286 | Val Loss: 1.0191 | Val Acc: 0.6145\n",
      "Epoch 15/30 | Train Loss: 481.9529 | Train Acc: 0.6346 | Val Loss: 1.0076 | Val Acc: 0.6160\n",
      "Epoch 16/30 | Train Loss: 479.0468 | Train Acc: 0.6401 | Val Loss: 1.0087 | Val Acc: 0.6090\n",
      "Epoch 17/30 | Train Loss: 471.2667 | Train Acc: 0.6389 | Val Loss: 0.9933 | Val Acc: 0.6185\n",
      "Epoch 18/30 | Train Loss: 470.1569 | Train Acc: 0.6424 | Val Loss: 1.0092 | Val Acc: 0.6205\n",
      "Epoch 19/30 | Train Loss: 466.5845 | Train Acc: 0.6443 | Val Loss: 1.0211 | Val Acc: 0.6050\n",
      "Epoch 20/30 | Train Loss: 461.9383 | Train Acc: 0.6446 | Val Loss: 1.0111 | Val Acc: 0.6200\n",
      "Epoch 21/30 | Train Loss: 460.0646 | Train Acc: 0.6495 | Val Loss: 1.0044 | Val Acc: 0.6240\n",
      "Epoch 22/30 | Train Loss: 455.9795 | Train Acc: 0.6477 | Val Loss: 0.9930 | Val Acc: 0.6255\n",
      "Epoch 23/30 | Train Loss: 453.1923 | Train Acc: 0.6506 | Val Loss: 1.0032 | Val Acc: 0.6250\n",
      "Epoch 24/30 | Train Loss: 449.2756 | Train Acc: 0.6522 | Val Loss: 0.9753 | Val Acc: 0.6260\n",
      "Epoch 25/30 | Train Loss: 446.1893 | Train Acc: 0.6571 | Val Loss: 0.9895 | Val Acc: 0.6210\n",
      "Epoch 26/30 | Train Loss: 443.1530 | Train Acc: 0.6612 | Val Loss: 1.0121 | Val Acc: 0.6100\n",
      "Epoch 27/30 | Train Loss: 439.3196 | Train Acc: 0.6656 | Val Loss: 0.9968 | Val Acc: 0.6200\n",
      "Epoch 28/30 | Train Loss: 437.0259 | Train Acc: 0.6664 | Val Loss: 0.9980 | Val Acc: 0.6295\n",
      "Epoch 29/30 | Train Loss: 433.3234 | Train Acc: 0.6702 | Val Loss: 0.9918 | Val Acc: 0.6180\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T23:02:15.068556Z",
     "start_time": "2025-07-16T23:02:14.803858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FCNNModel()\n",
    "model.load_state_dict(torch.load(\"../models/best_fcnn_model.pth\"))\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "evaluate(model, val_loader, criterion, label_encoder=label_encoder, device=device, return_metrics=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.40      0.47       275\n",
      "        fear       0.60      0.40      0.48       212\n",
      "         joy       0.75      0.74      0.74       704\n",
      "        love       0.53      0.28      0.37       178\n",
      "     sadness       0.55      0.81      0.66       550\n",
      "    surprise       0.45      0.36      0.40        81\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.57      0.50      0.52      2000\n",
      "weighted avg       0.62      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ]
}
